{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONWARNINGS=ignore\n"
     ]
    }
   ],
   "source": [
    "# We might need `imblearn`, so it's useful to install it if you haven't already!\n",
    "# !pip install imblearn\n",
    "\n",
    "import math                                                                                # Mathematical functions + calculations\n",
    "import warnings                                                                            # Warnings management\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd                                                                        # Data analysis + manipulation\n",
    "import numpy as np                                                                         # Array computations + mathematical functions\n",
    "import statsmodels.api as sm                                                               # Statistical computations for models\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN                                                      # Performs both under- and oversampling on a dataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV, RandomizedSearchCV      # Split data into random train and test subsets\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression                                        # Regressor model for classification cases\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier                             # Multilayer perceptron model for regression cases\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report # MSE and MAE used in model evaluation + overview evaluation features\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%env PYTHONWARNINGS=ignore\n",
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. HR Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Load and Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datasets/hr_data_new.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of entries for each column match the total entry count for the whole dataset, meaning that there are no null values. They were handled properly in Assignment 1.\n",
    "\n",
    "There were a number of operations done in the last assignment, including:\n",
    "- ~~Proportional stratified sampling~~\n",
    "- Encoding categorical features\n",
    "- Feature normalisation\n",
    "\n",
    "This means that I won't need to revisit these operations again for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the X and Y datasets then splitting them\n",
    "X = df.drop(\"is_promoted\", axis=1)\n",
    "y = df[\"is_promoted\"]\n",
    "\n",
    "print(\"=== Original dataset proportion ===\")\n",
    "print(y.value_counts())\n",
    "print(f\"Ratio (UP : P): {len(y[y == 0]) / len(y[y == 1])}\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=rng)\n",
    "X_train, y_train = SMOTEENN(random_state=rng).fit_resample(X_train, y_train)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rng)\n",
    "\n",
    "print(\"=== Post-split + sampled proportions ===\")\n",
    "print(\"Training set\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Ratio (UP : P): {len(y_train[y_train == 0]) / len(y_train[y_train == 1])}\")\n",
    "\n",
    "print(\"Testing set\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Ratio (UP : P): {len(y_test[y_test == 0]) / len(y_test[y_test == 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 and 1.3 Build the Model(s) + Evaluate and Improve the Model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression model is suitable for this test case because this problem's target features is a binary statement (a yes or no answer). We can build a binomial logistic regression classifier then later fine tune it as one possible model to evaluate in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing details about the data-model relationship\n",
    "lg_sm = sm.Logit(y_train, X_train).fit()\n",
    "lg_sm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[!]` With the original dataset from the notebook in Assignment 1, the p-values for all the features are 0.000. While lower p-values generally suggest higher confidence on the coefficients of the features, the fact that all of them are this low suggests a possible issue with the model and the dataset.\n",
    "\n",
    "I looked up to learn more about it and came to the possibility of two cases happening:\n",
    "- Perfect separation: the state where a particular combination of predictor variables perfectly predicts the outcome variable\n",
    "- Multicollinearity: the state where there is high correlation between two or more predictors)\n",
    "\n",
    "I found that the way sampling was done may have had a significant influence on the way this model learns and adapts. I was previously using stratified proportional sampling where the proportions remained the same as the imbalances attempt to even out, but that failed. This new method simply undersamples the majority class to match the amount in the minority class, and this significantly improved the model as seen in the f-score (initially with a score ~0.1 to now, ~0.6) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the classifier\n",
    "lg = LogisticRegression(max_iter=10000, random_state=rng)\n",
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the accuracy on the training and testing sets\n",
    "lg_train_cv = cross_validate(lg, X_train, y_train, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Training accuracy (logistic regression): {sum(lg_train_cv['test_accuracy']) / len(lg_train_cv['test_accuracy'])}\")\n",
    "\n",
    "lg_test_cv = cross_validate(lg, X_test, y_test, cv=skf, scoring=[\"accuracy\", \"f1\"])\n",
    "print(f\"Testing accuracy (logistic regression) : {sum(lg_test_cv['test_accuracy']) / len(lg_test_cv['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the model's performance through main classification metrics\n",
    "y_train_pred = lg.predict(X_train)\n",
    "\n",
    "print(\"=== Classification report (logistic regression, training set) ===\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lg.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report (logistic regression, testing set) ===\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying a combination of hyperparameters to determine the best for this classifier\n",
    "param_grid = {\n",
    "    \"penalty\": [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    \"max_iter\": [1000, 2000, 4000, 10000]\n",
    "}\n",
    "\n",
    "lg = LogisticRegression(random_state=rng)\n",
    "gs = GridSearchCV(lg, param_grid=param_grid, scoring=\"f1\", cv=skf, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Training f1-score (logistic regression, tuned): {gs.best_score_}\")\n",
    "    print(f\"Best combination (logistic regression, tuned) : {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the classifier\n",
    "lg = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the accuracy on the training and testing sets\n",
    "lg_train_cv = cross_validate(lg, X_train, y_train, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Training accuracy (logistic regression, tuned): {sum(lg_train_cv['test_accuracy']) / len(lg_train_cv['test_accuracy'])}\")\n",
    "\n",
    "lg_test_cv = cross_validate(lg, X_test, y_test, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Testing accuracy (logistic regression, tuned) : {sum(lg_test_cv['test_accuracy']) / len(lg_test_cv['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the model's performance through main classification metrics\n",
    "y_train_pred = lg.predict(X_train)\n",
    "\n",
    "print(\"=== Classification report (logistic regression, tuned, training set) ===\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lg.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report (logistic regression, tuned, testing set) ===\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can make the observation that the model is able to train sufficiently well on the training set as seen by its relatively high accuracy and F1 scores. The testing set shows a model with a higher accuracy at around the 90%, but I think that this is inaccurate. Displaying the classification report proved my point, with a higher precision, recall, and F1 score in the majority set (non-promoted employees) than those that who were.\n",
    "\n",
    "I can accept this model's behaviour though since there is a major disproportion in the test data. The recall of the minority class remains somewhat high though, meaning of all positive predictions, there are many employees in it that actually were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Multilayered Perceptron ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the classifier\n",
    "mlp = MLPClassifier(random_state=rng)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "    \n",
    "    mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the accuracy on the training and testing sets\n",
    "mlp_train_cv = cross_validate(lg, X_train, y_train, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Training accuracy (MLP ANN): {sum(mlp_train_cv['test_accuracy']) / len(mlp_train_cv['test_accuracy'])}\")\n",
    "\n",
    "mlp_test_cv = cross_validate(lg, X_test, y_test, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Testing accuracy (MLP ANN) : {sum(mlp_test_cv['test_accuracy']) / len(mlp_test_cv['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the model's performance through main classification metrics\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "\n",
    "print(\"=== Classification report (MLP ANN, training set) ===\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report (MLP ANN, testing set) ===\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying a combination of hyperparameters to determine the best combination\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(10, ), (25, ), (50, ), (100, )],\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "}\n",
    "mlp = MLPClassifier(random_state=rng)\n",
    "gs = RandomizedSearchCV(mlp, param_distributions=param_grid, scoring=\"f1\", cv=skf, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best combination (MLP ANN, tuned): {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the classifier\n",
    "mlp = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the accuracy on the training and testing sets\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    mlp_train_cv = cross_validate(mlp, X_train, y_train, cv=skf, scoring=[\"accuracy\"])\n",
    "    print(f\"Training accuracy (MLP ANN, tuned): {sum(mlp_train_cv['test_accuracy']) / len(mlp_train_cv['test_accuracy'])}\")\n",
    "\n",
    "    mlp_test_cv = cross_validate(mlp, X_test, y_test, cv=skf, scoring=[\"accuracy\"])\n",
    "    print(f\"Testing accuracy (MLP ANN, tuned) : {sum(mlp_test_cv['test_accuracy']) / len(mlp_test_cv['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the model's performance through main classification metrics\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "\n",
    "print(\"=== Classification report (MLP ANN, tuned, training set) ===\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report (MLP ANN, tuned, testing set) ===\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the classifier\n",
    "rf = RandomForestClassifier(random_state=rng)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the accuracy on the training and testing sets\n",
    "rf_train_cv = cross_validate(rf, X_train, y_train, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Training accuracy (random forest): {sum(rf_train_cv['test_accuracy']) / len(rf_train_cv['test_accuracy'])}\")\n",
    "\n",
    "rf_test_cv = cross_validate(rf, X_test, y_test, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Testing accuracy (random forest) : {sum(rf_test_cv['test_accuracy']) / len(rf_test_cv['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the model's performance through main classification metrics\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "print(\"=== Classification report (random forest, training set) ===\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report (random forest, testing set) ===\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tries a combination of hyperparameters to determine the best for this classifier\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [5, 10, 15],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"class_weight\": [\"balanced\", \"balanced_subsample\", None]\n",
    "}\n",
    "\n",
    "lg = RandomForestClassifier(random_state=rng)\n",
    "gs = GridSearchCV(lg, param_grid=param_grid, cv=skf, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best combination (random forest, tuned) : {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the classifier\n",
    "rf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the accuracy on the training and testing sets\n",
    "rf_train_cv = cross_validate(rf, X_train, y_train, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Training accuracy (random forest, tuned): {sum(rf_train_cv['test_accuracy']) / len(rf_train_cv['test_accuracy'])}\")\n",
    "\n",
    "rf_test_cv = cross_validate(rf, X_test, y_test, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Testing accuracy (random forest, tuned) : {sum(rf_test_cv['test_accuracy']) / len(rf_test_cv['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the model's performance through main classification metrics\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "print(\"=== Classification report (random forest, tuned, training set) ===\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report (random forest, tuned, testing set) ===\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the classifier\n",
    "xgb = XGBClassifier(objective=\"binary:logistic\", random_state=rng)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the accuracy on the training and testing sets\n",
    "xgb_train_cv = cross_validate(xgb, X_train, y_train, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Training accuracy (XGBoost): {sum(xgb_train_cv['test_accuracy']) / len(xgb_train_cv['test_accuracy'])}\")\n",
    "\n",
    "xgb_test_cv = cross_validate(xgb, X_test, y_test, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Testing accuracy (XGBoost) : {sum(xgb_test_cv['test_accuracy']) / len(xgb_test_cv['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the model's performance through main classification metrics\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "\n",
    "print(\"=== Classification report (XGBoost, training set) ===\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report (XGBoost, testing set) ===\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trying a combination of hyperparameters to determine the best for this classifier\n",
    "param_grid = {\n",
    "    \"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "    \"max_depth\": [5, 10, 15],\n",
    "    \"subsample\": [0, 0.5, 1],\n",
    "    \"sampling_method\": [\"uniform\", \"gradient_based\"],\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(objective=\"binary:logistic\", random_state=rng)\n",
    "gs = GridSearchCV(xgb, param_grid=param_grid, cv=skf, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best combination (XGBooster, tuned) : {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the classifier\n",
    "xgb = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the accuracy on the training and testing sets\n",
    "xgb_train_cv = cross_validate(lg, X_train, y_train, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Training accuracy (random forest): {sum(xgb_train_cv['test_accuracy']) / len(xgb_train_cv['test_accuracy'])}\")\n",
    "\n",
    "xgb_test_cv = cross_validate(lg, X_test, y_test, cv=skf, scoring=[\"accuracy\"])\n",
    "print(f\"Testing accuracy (random forest) : {sum(xgb_test_cv['test_accuracy']) / len(xgb_test_cv['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the model's performance through main classification metrics\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "\n",
    "print(\"=== Classification report (XGBoost, tuned, training set) ===\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report (XGBoost, tuned, testing set) ===\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Airbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Load and Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Region</td>\n",
       "      <td>Woodlands</td>\n",
       "      <td>1.44255</td>\n",
       "      <td>103.79580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>5.198497</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central Region</td>\n",
       "      <td>Bukit Timah</td>\n",
       "      <td>1.33235</td>\n",
       "      <td>103.78521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81</td>\n",
       "      <td>4.510860</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.246860</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North Region</td>\n",
       "      <td>Woodlands</td>\n",
       "      <td>1.44246</td>\n",
       "      <td>103.79667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>East Region</td>\n",
       "      <td>Tampines</td>\n",
       "      <td>1.34541</td>\n",
       "      <td>103.95712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>206</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.139762</td>\n",
       "      <td>0.967123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>East Region</td>\n",
       "      <td>Tampines</td>\n",
       "      <td>1.34567</td>\n",
       "      <td>103.95963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>0.198851</td>\n",
       "      <td>0.972603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group neighbourhood  latitude  longitude  room_type  price  \\\n",
       "0        North Region     Woodlands   1.44255  103.79580        1.0     83   \n",
       "1      Central Region   Bukit Timah   1.33235  103.78521        1.0     81   \n",
       "2        North Region     Woodlands   1.44246  103.79667        1.0     69   \n",
       "3         East Region      Tampines   1.34541  103.95712        1.0    206   \n",
       "4         East Region      Tampines   1.34567  103.95963        1.0     94   \n",
       "\n",
       "   minimum_nights  number_of_reviews  reviews_per_month  availability_365  \n",
       "0        5.198497           0.693147           0.009950          1.000000  \n",
       "1        4.510860           2.944439           0.246860          1.000000  \n",
       "2        1.945910           3.044522           0.182322          1.000000  \n",
       "3        0.693147           2.708050           0.139762          0.967123  \n",
       "4        0.693147           3.135494           0.198851          0.972603  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets/listings_new.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7497 entries, 0 to 7496\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   neighbourhood_group  7497 non-null   object \n",
      " 1   neighbourhood        7497 non-null   object \n",
      " 2   latitude             7497 non-null   float64\n",
      " 3   longitude            7497 non-null   float64\n",
      " 4   room_type            7497 non-null   float64\n",
      " 5   price                7497 non-null   int64  \n",
      " 6   minimum_nights       7497 non-null   float64\n",
      " 7   number_of_reviews    7497 non-null   float64\n",
      " 8   reviews_per_month    7497 non-null   float64\n",
      " 9   availability_365     7497 non-null   float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 585.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7497.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.314649</td>\n",
       "      <td>103.848951</td>\n",
       "      <td>1.456583</td>\n",
       "      <td>132.511538</td>\n",
       "      <td>1.857890</td>\n",
       "      <td>1.418348</td>\n",
       "      <td>0.376534</td>\n",
       "      <td>0.565316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.030615</td>\n",
       "      <td>0.044146</td>\n",
       "      <td>0.592793</td>\n",
       "      <td>82.146940</td>\n",
       "      <td>1.267354</td>\n",
       "      <td>1.448394</td>\n",
       "      <td>0.478031</td>\n",
       "      <td>0.400851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.245260</td>\n",
       "      <td>103.665470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.296010</td>\n",
       "      <td>103.836100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.311250</td>\n",
       "      <td>103.849810</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>0.701370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.322550</td>\n",
       "      <td>103.875350</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.620576</td>\n",
       "      <td>0.969863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.454590</td>\n",
       "      <td>103.973420</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>5.780744</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          latitude    longitude    room_type        price  minimum_nights  \\\n",
       "count  7497.000000  7497.000000  7497.000000  7497.000000     7497.000000   \n",
       "mean      1.314649   103.848951     1.456583   132.511538        1.857890   \n",
       "std       0.030615     0.044146     0.592793    82.146940        1.267354   \n",
       "min       1.245260   103.665470     0.000000     0.000000        0.693147   \n",
       "25%       1.296010   103.836100     1.000000    62.000000        0.693147   \n",
       "50%       1.311250   103.849810     2.000000   118.000000        1.386294   \n",
       "75%       1.322550   103.875350     2.000000   181.000000        2.397895   \n",
       "max       1.454590   103.973420     2.000000   378.000000        6.908755   \n",
       "\n",
       "       number_of_reviews  reviews_per_month  availability_365  \n",
       "count        7497.000000        7497.000000       7497.000000  \n",
       "mean            1.418348           0.376534          0.565316  \n",
       "std             1.448394           0.478031          0.400851  \n",
       "min             0.000000           0.000000          0.000000  \n",
       "25%             0.000000           0.000000          0.142466  \n",
       "50%             1.098612           0.157004          0.701370  \n",
       "75%             2.484907           0.620576          0.969863  \n",
       "max             5.780744           2.639057          1.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the hint given for this problem in the previous assignment, I opted to keep some parts of the dataset available but not for use by the model. Instead, it'll be used to split the dataset into further smaller subsets. That way, I can make specific models for a particular criteria (e.g., neighbourhood group) that might yield better results than if I were to create one generalised model for everything.\n",
    "\n",
    "Because there isn't much time, I have opted to pick two subsets to pursue for this problem:\n",
    "- A subset for listings in the Central region (`neighbourhood_group` is `Central`)\n",
    "- A subset for listings offering a private room (`room_type` is `Private room`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81</td>\n",
       "      <td>4.510860</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.906849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.756164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.836282</td>\n",
       "      <td>0.920548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.931507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>4.510860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5947 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neighbourhood  room_type  price  minimum_nights  number_of_reviews  \\\n",
       "1               0.0        1.0     81        4.510860           2.944439   \n",
       "10              1.0        1.0     44        2.772589           2.944439   \n",
       "11              1.0        1.0     40        3.433987           2.397895   \n",
       "12              2.0        1.0     65        1.098612           4.836282   \n",
       "13              1.0        1.0     44        3.433987           2.639057   \n",
       "...             ...        ...    ...             ...                ...   \n",
       "7492            6.0        2.0    100        1.386294           0.000000   \n",
       "7493            6.0        2.0    100        1.386294           0.000000   \n",
       "7494           11.0        1.0     58        3.433987           0.000000   \n",
       "7495            4.0        1.0     56        2.708050           0.000000   \n",
       "7496            4.0        1.0     65        4.510860           0.000000   \n",
       "\n",
       "      availability_365  \n",
       "1             1.000000  \n",
       "10            0.906849  \n",
       "11            0.756164  \n",
       "12            0.920548  \n",
       "13            0.931507  \n",
       "...                ...  \n",
       "7492          0.167123  \n",
       "7493          0.167123  \n",
       "7494          0.473973  \n",
       "7495          0.082192  \n",
       "7496          1.000000  \n",
       "\n",
       "[5947 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.902633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>81</td>\n",
       "      <td>4.510860</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.909589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.983562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>2.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7479</th>\n",
       "      <td>1.0</td>\n",
       "      <td>129</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      room_type  price  minimum_nights  number_of_reviews  availability_365\n",
       "44          1.0    100        5.902633           0.000000          1.000000\n",
       "59          1.0     49        2.944439           1.098612          0.986301\n",
       "60          1.0     81        4.510860           2.708050          0.000000\n",
       "68          1.0     56        2.944439           0.693147          0.909589\n",
       "77          1.0     40        2.944439           2.197225          0.983562\n",
       "...         ...    ...             ...                ...               ...\n",
       "7464        2.0    110        2.708050           0.000000          1.000000\n",
       "7469        1.0     49        2.944439           0.000000          0.983562\n",
       "7475        1.0     58        2.944439           0.000000          0.969863\n",
       "7479        1.0    129        1.386294           0.000000          0.260274\n",
       "7494        1.0     58        3.433987           0.000000          0.473973\n",
       "\n",
       "[993 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting the dataset into neighborhood groups and encoding the neighborhood categorical feature\n",
    "neighborhood_groups = [group for group in df.groupby(\"neighbourhood_group\", as_index=False)]\n",
    "neighborhoods = [group for group in df.groupby(\"neighbourhood\", as_index=False)]\n",
    "\n",
    "for group in neighborhood_groups:\n",
    "    group_df = group[1]\n",
    "    group_df[\"neighbourhood\"] = OrdinalEncoder(categories=[group_df[\"neighbourhood\"].unique()]).fit_transform(group_df[[\"neighbourhood\"]])\n",
    "    group_df.drop([\"neighbourhood_group\", \"reviews_per_month\", \"latitude\", \"longitude\"], axis=1, inplace=True)\n",
    "\n",
    "for group in neighborhoods:\n",
    "    group_df = group[1]\n",
    "    group_df.drop([\"neighbourhood_group\", \"neighbourhood\", \"reviews_per_month\", \"latitude\", \"longitude\"], axis=1, inplace=True)\n",
    "\n",
    "central_df = neighborhood_groups[0][1]\n",
    "kallang_df = neighborhoods[15][1]\n",
    "\n",
    "display(central_df)\n",
    "display(kallang_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 and 2.3 Build the Model(s) + Evaluate and Improve the Model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Central Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the X and Y datasets then splitting them\n",
    "X = central_df.drop(\"price\", axis=1)\n",
    "y = central_df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared (uncentered):</th>      <td>   0.855</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.854</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   4889.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 08 Feb 2024</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:44:16</td>     <th>  Log-Likelihood:    </th>          <td> -23118.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4162</td>      <th>  AIC:               </th>          <td>4.625e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4157</td>      <th>  BIC:               </th>          <td>4.628e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neighbourhood</th>     <td>    2.2333</td> <td>    0.205</td> <td>   10.903</td> <td> 0.000</td> <td>    1.832</td> <td>    2.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_type</th>         <td>   90.3100</td> <td>    1.260</td> <td>   71.693</td> <td> 0.000</td> <td>   87.840</td> <td>   92.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minimum_nights</th>    <td>  -12.7232</td> <td>    0.836</td> <td>  -15.220</td> <td> 0.000</td> <td>  -14.362</td> <td>  -11.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_reviews</th> <td>   -4.3168</td> <td>    0.643</td> <td>   -6.713</td> <td> 0.000</td> <td>   -5.577</td> <td>   -3.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>availability_365</th>  <td>   28.1919</td> <td>    2.386</td> <td>   11.816</td> <td> 0.000</td> <td>   23.514</td> <td>   32.869</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>555.962</td> <th>  Durbin-Watson:     </th> <td>   1.991</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 824.786</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.977</td>  <th>  Prob(JB):          </th> <td>7.94e-180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.970</td>  <th>  Cond. No.          </th> <td>    22.6</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  price   R-squared (uncentered):                   0.855\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.854\n",
       "Method:                 Least Squares   F-statistic:                              4889.\n",
       "Date:                Thu, 08 Feb 2024   Prob (F-statistic):                        0.00\n",
       "Time:                        22:44:16   Log-Likelihood:                         -23118.\n",
       "No. Observations:                4162   AIC:                                  4.625e+04\n",
       "Df Residuals:                    4157   BIC:                                  4.628e+04\n",
       "Df Model:                           5                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "neighbourhood         2.2333      0.205     10.903      0.000       1.832       2.635\n",
       "room_type            90.3100      1.260     71.693      0.000      87.840      92.780\n",
       "minimum_nights      -12.7232      0.836    -15.220      0.000     -14.362     -11.084\n",
       "number_of_reviews    -4.3168      0.643     -6.713      0.000      -5.577      -3.056\n",
       "availability_365     28.1919      2.386     11.816      0.000      23.514      32.869\n",
       "==============================================================================\n",
       "Omnibus:                      555.962   Durbin-Watson:                   1.991\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              824.786\n",
       "Skew:                           0.977   Prob(JB):                    7.94e-180\n",
       "Kurtosis:                       3.970   Cond. No.                         22.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing details about the data-model relationship\n",
    "lr_sm = sm.OLS(y_train, X_train).fit()\n",
    "lr_sm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the regressor\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (linear regression, Central listings): 62.614516152134044\n",
      "Training MAE (linear regression, Central listings) : 48.60042703468012\n",
      "Training R^2 (linear regression, Central listings) : 0.42285968479150976\n",
      "\n",
      "Testing RMSE (linear regression, Central listings) : 61.914760004667166\n",
      "Testing MAE (linear regression, Central listings)  : 48.18668693147375\n",
      "Testing R^2 (linear regression, Central listings)  : 0.4393384080090776\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "lr_train_cv = cross_validate(lr, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (linear regression, Central listings): {sum(np.sqrt(-lr_train_cv['test_neg_mean_squared_error'])) / len(lr_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (linear regression, Central listings) : {sum(-lr_train_cv['test_neg_mean_absolute_error']) / len(lr_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (linear regression, Central listings) : {sum(lr_train_cv['test_r2']) / len(lr_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "lr_test_cv = cross_validate(lr, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (linear regression, Central listings) : {sum(np.sqrt(-lr_test_cv['test_neg_mean_squared_error'])) / len(lr_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (linear regression, Central listings)  : {sum(-lr_test_cv['test_neg_mean_absolute_error']) / len(lr_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (linear regression, Central listings)  : {sum(lr_test_cv['test_r2']) / len(lr_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the model for external use\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "\n",
    "pickle.dump(lr, open(\"Models/central_lr.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the regressor\n",
    "svm = SVR()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (SVR, Central listings): 76.61187752834294\n",
      "Training MAE (SVR, Central listings) : 57.95632428197242\n",
      "Training R^2 (SVR, Central listings) : 0.13650947884049303\n",
      "\n",
      "Testing RMSE (SVR, Central listings) : 80.00573921993806\n",
      "Testing MAE (SVR, Central listings)  : 61.94573222463043\n",
      "Testing R^2 (SVR, Central listings)  : 0.06446892523847816\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "svm_train_cv = cross_validate(svm, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (SVR, Central listings): {sum(np.sqrt(-svm_train_cv['test_neg_mean_squared_error'])) / len(svm_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (SVR, Central listings) : {sum(-svm_train_cv['test_neg_mean_absolute_error']) / len(svm_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (SVR, Central listings) : {sum(svm_train_cv['test_r2']) / len(svm_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "svm_test_cv = cross_validate(svm, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (SVR, Central listings) : {sum(np.sqrt(-svm_test_cv['test_neg_mean_squared_error'])) / len(svm_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (SVR, Central listings)  : {sum(-svm_test_cv['test_neg_mean_absolute_error']) / len(svm_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (SVR, Central listings)  : {sum(svm_test_cv['test_r2']) / len(svm_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination (SVR, tuned, Central listings): {'C': 100, 'epsilon': 0.2, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Tries a combination of hyperparameters to determine the best for this regressor\n",
    "param_grid = { \n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"epsilon\": [0.1, 0.2, 0.3, 0.4]\n",
    "}\n",
    "svm = SVR()\n",
    "gs = GridSearchCV(svm, param_grid=param_grid, scoring=\"r2\", cv=5, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best combination (SVR, tuned, Central listings): {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the regressor\n",
    "svm = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (SVR, tuned, Central listings): 63.24343765507801\n",
      "Training MAE (SVR, tuned, Central listings) : 45.28343285440935\n",
      "Training R^2 (SVR, tuned, Central listings) : 0.42526065129946417\n",
      "\n",
      "Testing RMSE (SVR, tuned, Central listings) : 61.507630856678205\n",
      "Testing MAE (SVR, tuned, Central listings)  : 43.61076497816154\n",
      "Testing R^2 (SVR, tuned, Central listings)  : 0.41354110138611777\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "svm_train_cv = cross_validate(svm, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (SVR, tuned, Central listings): {sum(np.sqrt(-svm_train_cv['test_neg_mean_squared_error'])) / len(svm_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (SVR, tuned, Central listings) : {sum(-svm_train_cv['test_neg_mean_absolute_error']) / len(svm_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (SVR, tuned, Central listings) : {sum(svm_train_cv['test_r2']) / len(svm_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "svm_test_cv = cross_validate(svm, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (SVR, tuned, Central listings) : {sum(np.sqrt(-svm_test_cv['test_neg_mean_squared_error'])) / len(svm_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (SVR, tuned, Central listings)  : {sum(-svm_test_cv['test_neg_mean_absolute_error']) / len(svm_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (SVR, tuned, Central listings)  : {sum(svm_test_cv['test_r2']) / len(svm_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the model for external use\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "\n",
    "pickle.dump(svm, open(\"Models/central_svm.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Multi-layered Perceptron ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the regressor\n",
    "mlp = MLPRegressor(random_state=rng)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "    \n",
    "    mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (MLP ANN, Central listings): 62.456901785664954\n",
      "Training MAE (MLP ANN, Central listings) : 48.42957855094611\n",
      "Training R^2 (MLP ANN, Central listings) : 0.42580454123258776\n",
      "\n",
      "Testing RMSE (MLP ANN, Central listings) : 62.817824339447796\n",
      "Testing MAE (MLP ANN, Central listings)  : 49.61645048283369\n",
      "Testing R^2 (MLP ANN, Central listings)  : 0.42302227244997087\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    mlp_train_cv = cross_validate(mlp, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "    print(f\"Training RMSE (MLP ANN, Central listings): {sum(np.sqrt(-mlp_train_cv['test_neg_mean_squared_error'])) / len(mlp_train_cv['test_neg_mean_squared_error'])}\")\n",
    "    print(f\"Training MAE (MLP ANN, Central listings) : {sum(-mlp_train_cv['test_neg_mean_absolute_error']) / len(mlp_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"Training R^2 (MLP ANN, Central listings) : {sum(mlp_train_cv['test_r2']) / len(mlp_train_cv['test_r2'])}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    mlp_test_cv = cross_validate(mlp, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "    print(f\"Testing RMSE (MLP ANN, Central listings) : {sum(np.sqrt(-mlp_test_cv['test_neg_mean_squared_error'])) / len(mlp_test_cv['test_neg_mean_squared_error'])}\")\n",
    "    print(f\"Testing MAE (MLP ANN, Central listings)  : {sum(-mlp_test_cv['test_neg_mean_absolute_error']) / len(mlp_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"Testing R^2 (MLP ANN, Central listings)  : {sum(mlp_test_cv['test_r2']) / len(mlp_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[!]` The initial training and testing accuracies for a base model MLP regressor (with no hyperparameter customisation) are extremely low. We will need to continue customising the hyperparameters to better suit the use case and (hopefully) improve the accuracy and other metrics overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination (MLP ANN, tuned, Central listings): {'activation': 'logistic', 'hidden_layer_sizes': (30,), 'max_iter': 4000, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Tries a combination of hyperparameters to determine the best for this regressor\n",
    "param_grid = { \n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"], \n",
    "    \"hidden_layer_sizes\": [(5, ), (10, ), (20, ), (30, ), (40, )], \n",
    "    \"max_iter\": [500, 1000, 2000, 4000, 10000], \n",
    "    \"solver\": [\"sgd\", \"adam\"]\n",
    "}\n",
    "mlp = MLPRegressor(random_state=rng)\n",
    "gs = GridSearchCV(mlp, param_grid=param_grid, scoring=\"r2\", cv=5, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best combination (MLP ANN, tuned, Central listings): {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the regressor\n",
    "mlp = gs.best_estimator_\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "    \n",
    "    mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (MLP ANN, tuned, Central listings): 60.033527293586\n",
      "Training MAE (MLP ANN, tuned, Central listings) : 45.89981998328368\n",
      "Training R^2 (MLP ANN, tuned, Central listings) : 0.4694939475536522\n",
      "\n",
      "Testing RMSE (MLP ANN, tuned, Central listings) : 60.51266777019631\n",
      "Testing MAE (MLP ANN, tuned, Central listings)  : 46.43238901098526\n",
      "Testing R^2 (MLP ANN, tuned, Central listings)  : 0.46455917278234526\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    mlp_train_cv = cross_validate(mlp, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "    print(f\"Training RMSE (MLP ANN, tuned, Central listings): {sum(np.sqrt(-mlp_train_cv['test_neg_mean_squared_error'])) / len(mlp_train_cv['test_neg_mean_squared_error'])}\")\n",
    "    print(f\"Training MAE (MLP ANN, tuned, Central listings) : {sum(-mlp_train_cv['test_neg_mean_absolute_error']) / len(mlp_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"Training R^2 (MLP ANN, tuned, Central listings) : {sum(mlp_train_cv['test_r2']) / len(mlp_train_cv['test_r2'])}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    mlp_test_cv = cross_validate(mlp, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "    print(f\"Testing RMSE (MLP ANN, tuned, Central listings) : {sum(np.sqrt(-mlp_test_cv['test_neg_mean_squared_error'])) / len(mlp_test_cv['test_neg_mean_squared_error'])}\")\n",
    "    print(f\"Testing MAE (MLP ANN, tuned, Central listings)  : {sum(-mlp_test_cv['test_neg_mean_absolute_error']) / len(mlp_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"Testing R^2 (MLP ANN, tuned, Central listings)  : {sum(mlp_test_cv['test_r2']) / len(mlp_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the model for external use\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "\n",
    "pickle.dump(mlp, open(\"Models/central_mlp.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(random_state=RandomState(MT19937) at 0x7FD9E19A5D40)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the regressor\n",
    "ab = AdaBoostRegressor(random_state=rng)\n",
    "ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (AdaBoost, Central listings): 64.78528744201321\n",
      "Training MAE (AdaBoost, Central listings) : 54.08566039780307\n",
      "Training R^2 (AdaBoost, Central listings) : 0.38177356822182884\n",
      "\n",
      "Testing RMSE (AdaBoost, Central listings) : 63.808719606695036\n",
      "Testing MAE (AdaBoost, Central listings)  : 52.814701848838844\n",
      "Testing R^2 (AdaBoost, Central listings)  : 0.40366242817158576\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "ab_train_cv = cross_validate(ab, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (AdaBoost, Central listings): {sum(np.sqrt(-ab_train_cv['test_neg_mean_squared_error'])) / len(ab_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (AdaBoost, Central listings) : {sum(-ab_train_cv['test_neg_mean_absolute_error']) / len(ab_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (AdaBoost, Central listings) : {sum(ab_train_cv['test_r2']) / len(ab_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "ab_test_cv = cross_validate(ab, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (AdaBoost, Central listings) : {sum(np.sqrt(-ab_test_cv['test_neg_mean_squared_error'])) / len(ab_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (AdaBoost, Central listings)  : {sum(-ab_test_cv['test_neg_mean_absolute_error']) / len(ab_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (AdaBoost, Central listings)  : {sum(ab_test_cv['test_r2']) / len(ab_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination (AdaBoost, tuned, Central listings) : {'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tries a combination of hyperparameters to determine the best for this classifier\n",
    "param_grid = {\n",
    "    \"n_estimators\": [25, 50, 75, 100],\n",
    "    \"learning_rate\": [0.01, 0.25, 0.5, 0.75, 1],\n",
    "    \"loss\": [\"linear\", \"square\", \"exponential\"]\n",
    "}\n",
    "\n",
    "ab = AdaBoostRegressor(random_state=rng)\n",
    "gs = GridSearchCV(ab, param_grid=param_grid, scoring=\"r2\", cv=5, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best combination (AdaBoost, tuned, Central listings) : {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the regressor\n",
    "ab = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (AdaBoost, tuned, Central listings): 61.93257804000176\n",
      "Training MAE (AdaBoost, tuned, Central listings) : 48.38712556137786\n",
      "Training R^2 (AdaBoost, tuned, Central listings) : 0.4350576404766001\n",
      "\n",
      "Testing RMSE (AdaBoost, tuned, Central listings) : 61.84684556080165\n",
      "Testing MAE (AdaBoost, tuned, Central listings)  : 48.15115008783186\n",
      "Testing R^2 (AdaBoost, tuned, Central listings)  : 0.4399438318182353\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "ab_train_cv = cross_validate(ab, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (AdaBoost, tuned, Central listings): {sum(np.sqrt(-ab_train_cv['test_neg_mean_squared_error'])) / len(ab_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (AdaBoost, tuned, Central listings) : {sum(-ab_train_cv['test_neg_mean_absolute_error']) / len(ab_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (AdaBoost, tuned, Central listings) : {sum(ab_train_cv['test_r2']) / len(ab_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "ab_test_cv = cross_validate(ab, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (AdaBoost, tuned, Central listings) : {sum(np.sqrt(-ab_test_cv['test_neg_mean_squared_error'])) / len(ab_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (AdaBoost, tuned, Central listings)  : {sum(-ab_test_cv['test_neg_mean_absolute_error']) / len(ab_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (AdaBoost, tuned, Central listings)  : {sum(ab_test_cv['test_r2']) / len(ab_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the model for external use\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "\n",
    "pickle.dump(ab, open(\"Models/central_ab.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Kallang listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the X and Y datasets then splitting them\n",
    "X = kallang_df.drop(\"price\", axis=1)\n",
    "y = kallang_df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared (uncentered):</th>      <td>   0.824</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.823</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   807.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 08 Feb 2024</td> <th>  Prob (F-statistic):</th>          <td>1.05e-258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:49:47</td>     <th>  Log-Likelihood:    </th>          <td> -3873.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   695</td>      <th>  AIC:               </th>          <td>   7754.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   691</td>      <th>  BIC:               </th>          <td>   7772.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_type</th>         <td>   97.0666</td> <td>    3.189</td> <td>   30.438</td> <td> 0.000</td> <td>   90.805</td> <td>  103.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minimum_nights</th>    <td>  -15.9476</td> <td>    2.160</td> <td>   -7.384</td> <td> 0.000</td> <td>  -20.188</td> <td>  -11.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_reviews</th> <td>    1.8011</td> <td>    1.610</td> <td>    1.119</td> <td> 0.264</td> <td>   -1.360</td> <td>    4.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>availability_365</th>  <td>   27.3428</td> <td>    5.848</td> <td>    4.676</td> <td> 0.000</td> <td>   15.861</td> <td>   38.824</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>111.432</td> <th>  Durbin-Watson:     </th> <td>   1.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 175.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.041</td>  <th>  Prob(JB):          </th> <td>9.18e-39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.308</td>  <th>  Cond. No.          </th> <td>    7.32</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  price   R-squared (uncentered):                   0.824\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.823\n",
       "Method:                 Least Squares   F-statistic:                              807.2\n",
       "Date:                Thu, 08 Feb 2024   Prob (F-statistic):                   1.05e-258\n",
       "Time:                        22:49:47   Log-Likelihood:                         -3873.0\n",
       "No. Observations:                 695   AIC:                                      7754.\n",
       "Df Residuals:                     691   BIC:                                      7772.\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "room_type            97.0666      3.189     30.438      0.000      90.805     103.328\n",
       "minimum_nights      -15.9476      2.160     -7.384      0.000     -20.188     -11.707\n",
       "number_of_reviews     1.8011      1.610      1.119      0.264      -1.360       4.962\n",
       "availability_365     27.3428      5.848      4.676      0.000      15.861      38.824\n",
       "==============================================================================\n",
       "Omnibus:                      111.432   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              175.168\n",
       "Skew:                           1.041   Prob(JB):                     9.18e-39\n",
       "Kurtosis:                       4.308   Cond. No.                         7.32\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing details about the data-model relationship\n",
    "lr_sm = sm.OLS(y_train, X_train).fit()\n",
    "lr_sm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the regressor\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (linear regression, Kallang listings): 64.0229950612638\n",
      "Training MAE (linear regression, Kallang listings) : 48.77472371196027\n",
      "Training R^2 (linear regression, Kallang listings) : 0.44884484645932315\n",
      "\n",
      "Testing RMSE (linear regression, Kallang listings) : 56.96665612967121\n",
      "Testing MAE (linear regression, Kallang listings)  : 43.35939325581402\n",
      "Testing R^2 (linear regression, Kallang listings)  : 0.5293206596856599\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "lr_train_cv = cross_validate(lr, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (linear regression, Kallang listings): {sum(np.sqrt(-lr_train_cv['test_neg_mean_squared_error'])) / len(lr_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (linear regression, Kallang listings) : {sum(-lr_train_cv['test_neg_mean_absolute_error']) / len(lr_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (linear regression, Kallang listings) : {sum(lr_train_cv['test_r2']) / len(lr_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "lr_test_cv = cross_validate(lr, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (linear regression, Kallang listings) : {sum(np.sqrt(-lr_test_cv['test_neg_mean_squared_error'])) / len(lr_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (linear regression, Kallang listings)  : {sum(-lr_test_cv['test_neg_mean_absolute_error']) / len(lr_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (linear regression, Kallang listings)  : {sum(lr_test_cv['test_r2']) / len(lr_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the model for external use\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "\n",
    "pickle.dump(lr, open(\"Models/kallang_lr.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the regressor\n",
    "svm = SVR()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (SVR, Kallang listings): 79.27903720089148\n",
      "Training MAE (SVR, Kallang listings) : 56.681451608911175\n",
      "Training R^2 (SVR, Kallang listings) : 0.15999775396422258\n",
      "\n",
      "Testing RMSE (SVR, Kallang listings) : 77.5249607846248\n",
      "Testing MAE (SVR, Kallang listings)  : 61.68478597571823\n",
      "Testing R^2 (SVR, Kallang listings)  : 0.13871332922888568\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "svm_train_cv = cross_validate(svm, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (SVR, Kallang listings): {sum(np.sqrt(-svm_train_cv['test_neg_mean_squared_error'])) / len(svm_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (SVR, Kallang listings) : {sum(-svm_train_cv['test_neg_mean_absolute_error']) / len(svm_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (SVR, Kallang listings) : {sum(svm_train_cv['test_r2']) / len(svm_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "svm_test_cv = cross_validate(svm, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (SVR, Kallang listings) : {sum(np.sqrt(-svm_test_cv['test_neg_mean_squared_error'])) / len(svm_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (SVR, Kallang listings)  : {sum(-svm_test_cv['test_neg_mean_absolute_error']) / len(svm_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (SVR, Kallang listings)  : {sum(svm_test_cv['test_r2']) / len(svm_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination (SVR, tuned, Kallang listings): {'C': 100, 'epsilon': 0.4, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Tries a combination of hyperparameters to determine the best for this regressor\n",
    "param_grid = { \n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"epsilon\": [0.1, 0.2, 0.3, 0.4]\n",
    "}\n",
    "svm = SVR()\n",
    "gs = GridSearchCV(svm, param_grid=param_grid, scoring=\"r2\", cv=5, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best combination (SVR, tuned, Kallang listings): {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the regressor\n",
    "svm = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (SVR, tuned, Kallang listings): 63.17251662176267\n",
      "Training MAE (SVR, tuned, Kallang listings) : 42.69706968799497\n",
      "Training R^2 (SVR, tuned, Kallang listings) : 0.46549092006105114\n",
      "\n",
      "Testing RMSE (SVR, tuned, Kallang listings) : 57.616946408608364\n",
      "Testing MAE (SVR, tuned, Kallang listings)  : 40.635313058048425\n",
      "Testing R^2 (SVR, tuned, Kallang listings)  : 0.5199235831156366\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "svm_train_cv = cross_validate(svm, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (SVR, tuned, Kallang listings): {sum(np.sqrt(-svm_train_cv['test_neg_mean_squared_error'])) / len(svm_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (SVR, tuned, Kallang listings) : {sum(-svm_train_cv['test_neg_mean_absolute_error']) / len(svm_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (SVR, tuned, Kallang listings) : {sum(svm_train_cv['test_r2']) / len(svm_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "svm_test_cv = cross_validate(svm, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (SVR, tuned, Kallang listings) : {sum(np.sqrt(-svm_test_cv['test_neg_mean_squared_error'])) / len(svm_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (SVR, tuned, Kallang listings)  : {sum(-svm_test_cv['test_neg_mean_absolute_error']) / len(svm_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (SVR, tuned, Kallang listings)  : {sum(svm_test_cv['test_r2']) / len(svm_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the model for external use\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "\n",
    "pickle.dump(svm, open(\"Models/kallang_svm.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Multi-layered Perceptron ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the regressor\n",
    "mlp = MLPRegressor(random_state=rng)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "    \n",
    "    mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (MLP ANN, Kallang listings): 84.19985911352671\n",
      "Training MAE (MLP ANN, Kallang listings) : 66.193289653244\n",
      "Training R^2 (MLP ANN, Kallang listings) : 0.051439129350281165\n",
      "\n",
      "Testing RMSE (MLP ANN, Kallang listings) : 89.09061866153623\n",
      "Testing MAE (MLP ANN, Kallang listings)  : 69.78930333824445\n",
      "Testing R^2 (MLP ANN, Kallang listings)  : -0.13886575266334272\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    mlp_train_cv = cross_validate(mlp, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "    print(f\"Training RMSE (MLP ANN, Kallang listings): {sum(np.sqrt(-mlp_train_cv['test_neg_mean_squared_error'])) / len(mlp_train_cv['test_neg_mean_squared_error'])}\")\n",
    "    print(f\"Training MAE (MLP ANN, Kallang listings) : {sum(-mlp_train_cv['test_neg_mean_absolute_error']) / len(mlp_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"Training R^2 (MLP ANN, Kallang listings) : {sum(mlp_train_cv['test_r2']) / len(mlp_train_cv['test_r2'])}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    mlp_test_cv = cross_validate(mlp, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "    print(f\"Testing RMSE (MLP ANN, Kallang listings) : {sum(np.sqrt(-mlp_test_cv['test_neg_mean_squared_error'])) / len(mlp_test_cv['test_neg_mean_squared_error'])}\")\n",
    "    print(f\"Testing MAE (MLP ANN, Kallang listings)  : {sum(-mlp_test_cv['test_neg_mean_absolute_error']) / len(mlp_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"Testing R^2 (MLP ANN, Kallang listings)  : {sum(mlp_test_cv['test_r2']) / len(mlp_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[!]` The initial training and testing accuracies for a base model MLP regressor (with no hyperparameter customisation) are extremely low. We will need to continue customising the hyperparameters to better suit the use case and (hopefully) improve the accuracy and other metrics overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination (MLP ANN, tuned, Kallang listings): {'activation': 'logistic', 'hidden_layer_sizes': (40,), 'max_iter': 1000, 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "# Tries a combination of hyperparameters to determine the best for this regressor\n",
    "param_grid = { \n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"], \n",
    "    \"hidden_layer_sizes\": [(5, ), (10, ), (20, ), (30, ), (40, )], \n",
    "    \"max_iter\": [500, 1000, 2000, 4000, 10000], \n",
    "    \"solver\": [\"sgd\", \"adam\"]\n",
    "}\n",
    "mlp = MLPRegressor(random_state=rng)\n",
    "gs = GridSearchCV(mlp, param_grid=param_grid, scoring=\"r2\", cv=5, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best combination (MLP ANN, tuned, Kallang listings): {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the regressor\n",
    "mlp = gs.best_estimator_\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # Temporarily ignores warnings\n",
    "    \n",
    "    mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (MLP ANN, tuned, Kallang listings): 59.72662202878612\n",
      "Training MAE (MLP ANN, tuned, Kallang listings) : 42.93076308758805\n",
      "Training R^2 (MLP ANN, tuned, Kallang listings) : 0.5201942623987728\n",
      "\n",
      "Testing RMSE (MLP ANN, tuned, Kallang listings) : 55.28872269744638\n",
      "Testing MAE (MLP ANN, tuned, Kallang listings)  : 41.73193899831987\n",
      "Testing R^2 (MLP ANN, tuned, Kallang listings)  : 0.5582557205517306\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    mlp_train_cv = cross_validate(mlp, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "    print(f\"Training RMSE (MLP ANN, tuned, Kallang listings): {sum(np.sqrt(-mlp_train_cv['test_neg_mean_squared_error'])) / len(mlp_train_cv['test_neg_mean_squared_error'])}\")\n",
    "    print(f\"Training MAE (MLP ANN, tuned, Kallang listings) : {sum(-mlp_train_cv['test_neg_mean_absolute_error']) / len(mlp_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"Training R^2 (MLP ANN, tuned, Kallang listings) : {sum(mlp_train_cv['test_r2']) / len(mlp_train_cv['test_r2'])}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    mlp_test_cv = cross_validate(mlp, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "    print(f\"Testing RMSE (MLP ANN, tuned, Kallang listings) : {sum(np.sqrt(-mlp_test_cv['test_neg_mean_squared_error'])) / len(mlp_test_cv['test_neg_mean_squared_error'])}\")\n",
    "    print(f\"Testing MAE (MLP ANN, tuned, Kallang listings)  : {sum(-mlp_test_cv['test_neg_mean_absolute_error']) / len(mlp_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"Testing R^2 (MLP ANN, tuned, Kallang listings)  : {sum(mlp_test_cv['test_r2']) / len(mlp_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the model for external use\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "\n",
    "pickle.dump(mlp, open(\"Models/kallang_mlp.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(random_state=RandomState(MT19937) at 0x7FD9E19A5D40)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the regressor\n",
    "ab = AdaBoostRegressor(random_state=rng)\n",
    "ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (AdaBoost, Kallang listings): 62.54788401319718\n",
      "Training MAE (AdaBoost, Kallang listings) : 48.09927471146036\n",
      "Training R^2 (AdaBoost, Kallang listings) : 0.47205290404532174\n",
      "\n",
      "Testing RMSE (AdaBoost, Kallang listings) : 55.54132974355154\n",
      "Testing MAE (AdaBoost, Kallang listings)  : 45.20656349721365\n",
      "Testing R^2 (AdaBoost, Kallang listings)  : 0.5545474498949552\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "ab_train_cv = cross_validate(ab, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (AdaBoost, Kallang listings): {sum(np.sqrt(-ab_train_cv['test_neg_mean_squared_error'])) / len(ab_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (AdaBoost, Kallang listings) : {sum(-ab_train_cv['test_neg_mean_absolute_error']) / len(ab_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (AdaBoost, Kallang listings) : {sum(ab_train_cv['test_r2']) / len(ab_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "ab_test_cv = cross_validate(ab, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (AdaBoost, Kallang listings) : {sum(np.sqrt(-ab_test_cv['test_neg_mean_squared_error'])) / len(ab_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (AdaBoost, Kallang listings)  : {sum(-ab_test_cv['test_neg_mean_absolute_error']) / len(ab_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (AdaBoost, Kallang listings)  : {sum(ab_test_cv['test_r2']) / len(ab_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination (AdaBoost, tuned, Kallang listings) : {'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Tries a combination of hyperparameters to determine the best for this classifier\n",
    "param_grid = {\n",
    "    \"n_estimators\": [25, 50, 75, 100],\n",
    "    \"learning_rate\": [0.01, 0.25, 0.5, 0.75, 1],\n",
    "    \"loss\": [\"linear\", \"square\", \"exponential\"]\n",
    "}\n",
    "\n",
    "ab = AdaBoostRegressor(random_state=rng)\n",
    "gs = GridSearchCV(ab, param_grid=param_grid, scoring=\"r2\", cv=5, n_jobs=-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best combination (AdaBoost, tuned, Kallang listings) : {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(learning_rate=0.01, loss='square',\n",
       "                  random_state=RandomState(MT19937) at 0x7FD9902A3C40)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the regressor\n",
    "ab = gs.best_estimator_\n",
    "ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE (AdaBoost, tuned, Kallang listings): 59.355791748060184\n",
      "Training MAE (AdaBoost, tuned, Kallang listings) : 43.68690086695187\n",
      "Training R^2 (AdaBoost, tuned, Kallang listings) : 0.5248691709830616\n",
      "\n",
      "Testing RMSE (AdaBoost, tuned, Kallang listings) : 55.93816693022692\n",
      "Testing MAE (AdaBoost, tuned, Kallang listings)  : 42.302844182426256\n",
      "Testing R^2 (AdaBoost, tuned, Kallang listings)  : 0.5490976832479322\n"
     ]
    }
   ],
   "source": [
    "# Determining important metrics on the training and testing sets\n",
    "ab_train_cv = cross_validate(ab, X_train, y_train, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Training RMSE (AdaBoost, tuned, Kallang listings): {sum(np.sqrt(-ab_train_cv['test_neg_mean_squared_error'])) / len(ab_train_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Training MAE (AdaBoost, tuned, Kallang listings) : {sum(-ab_train_cv['test_neg_mean_absolute_error']) / len(ab_train_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Training R^2 (AdaBoost, tuned, Kallang listings) : {sum(ab_train_cv['test_r2']) / len(ab_train_cv['test_r2'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "ab_test_cv = cross_validate(ab, X_test, y_test, scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"], cv=5)\n",
    "print(f\"Testing RMSE (AdaBoost, tuned, Kallang listings) : {sum(np.sqrt(-ab_test_cv['test_neg_mean_squared_error'])) / len(ab_test_cv['test_neg_mean_squared_error'])}\")\n",
    "print(f\"Testing MAE (AdaBoost, tuned, Kallang listings)  : {sum(-ab_test_cv['test_neg_mean_absolute_error']) / len(ab_test_cv['test_neg_mean_absolute_error'])}\")\n",
    "print(f\"Testing R^2 (AdaBoost, tuned, Kallang listings)  : {sum(ab_test_cv['test_r2']) / len(ab_test_cv['test_r2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the model for external use\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "\n",
    "pickle.dump(ab, open(\"Models/kallang_ab.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
